---
title: "Human vs AI Music Generation Services"
description: "Musiversal is awesome and AI music still sucks"
date: 2025-08-10
draft: true
tags:
  - AI
  - music
  - musiversal
---

This post is about two things related to making music:
1. Making music with remote professionals is amazing and getting even better.
2. AI music generation exists.

## Making music with real people is the best
I love making music. I'm an amateur and have made three albums with my band at professional studios.

Studios are expensive though, especially if you just want to make a song or two at a time.

Enter home studios! Here's what you need:
- A space to record the music
- Recording hardware and software
- The skills to record each instrument
- The skills to edit the tracks
- The skills to mix the tracks

If you want to the recording to be good, then everything's gotta be good. Good room acoustics, good equipment, good skills.

Good musicians too.

### Enter music services

I have some experience with these services:
- [fiverr](https://www.fiverr.com/)
- [airgigs](https://www.airgigs.com/)
- [musiversal](https://musiversal.com/)

With Fiverr and Airgigs, you find a person, upload your files and notes, then the person does the work and sends you back the audio files. All communication is written. I've used both and have had good experiences. I still plan on using them occasionally, but I'm in a honeymoon phase with musiversal.

There are two things very different about musiversal, and they're game changers.
1. You pay a flat monthly fee to book "unlimited" sessions, with the restriction that you can have up to 4 sessions queued at a time. There's a wait time for each service, with the average for me so far of 2-5 days, so I can queue up a lot of sessions in a month.
2. You can choose to observe and talk during the session. It's a video call with their DAW (audio recording software) as the screenshare. This is huge because you can give real-time feedback during the session; something you can't do with any other service I'm aware of.

### It's amazing

I have a big pile of partial song ideas that I've wanted to finish and record, but haven't for those reasons I mentioned above.
Musiversal gets me past all those barriers. It being a subscription service gives me a nudge to finish the songs too.

The sessions are the best part. Book a 30-minute session with someone who's had 15 minutes to prep, then watch them nail the part after one or two tries. Polish a couple spots and try another idea or two. Fast, efficient, impressive, delightful. By the end I'm gushing with excitement over what they've brought to my little idea.

There's a lot of editing of those raw tracks that needs to happen, so I've used sessions for that too. You don't have to participate in those sessions, but I joined the first one to watch and learn. These editors are pros, and it's magical to watch because they're so fast and proficient.

### I hope it thrives

These online music services are great for consumers, but it's a tough gig for the musicians and other professionals, especially for those starting out. I know each location's cost of living is a factor on whether the wages work or not for people. Another thing I like about musiversal is that it appears they're paying a fixed monthly rate to their artists. This helps create a more stable income situation for them. Whether it's enough, I don't know, but I hope so.

## AI music is just AI

I asked claude.ai, "_What is the simplest way to express how AI generates **results**? As in, what is a one sentence explanation of what the LLM is doing when it generates **output** based on an input?_"

> An LLM generates output by predicting the most likely next word (or token) based on the input text and all the patterns it learned during training, repeating this process one word at a time until it completes the response.

Then I asked, "_What is the simplest way to express how AI generates **music**? As in, what is a one sentence explanation of what the LLM is doing when it generates **music** based on an input?_"

> The LLM predicts the most likely next musical element (note, chord, or audio token) based on patterns it learned from training data, similar to how it predicts the next word in text but applied to musical sequences.

That's the most accurate description of AI music in my opinion. You get what it thinks the most likely output should be given the context. It's not creating anything new. Like most people. So how does it compare today?

### Human versus AI - guitar riffs

Google has an AI music generation tool currently in beta. One of its features is called "Extend", where you give it a music clip and instructions, and it'll generate a chunk of audio. I tried it today by giving it guitar riffs for a song I'm working on.

I fed it three different sections: a verse, pre-chorus, and chorus, prompting it to generate the next section.

Each prompt looked like this:
"_I uploaded a guitar verse for an alt-rock song. Create pre-chorus guitar ideas based on it. Don't include any other instruments aside from a guitar that sounds like it's the same guitar in the output._"
Here's what it made:

| Guitar Riff       |                                                                                                                    |
|:------------------|--------------------------------------------------------------------------------------------------------------------|
| Actual verse      | <audio controls preload="metadata"><source src="/music-generation/actual-verse.mp3" type="audio/mpeg"></audio>     |
| Actual pre-chorus | <audio controls preload="metadata"><source src="/music-generation/actual-prechorus.mp3" type="audio/mpeg"></audio> |
| Actual chorus     | <audio controls preload="metadata"><source src="/music-generation/actual-chorus.mp3" type="audio/mpeg"></audio>    |
| Actual bridge     | <audio controls preload="metadata"><source src="/music-generation/actual-bridge.mp3" type="audio/mpeg"></audio>    |
| AI pre-chorus     | <audio controls preload="metadata"><source src="/music-generation/ai-prechorus.mp3" type="audio/mpeg"></audio>     |
| AI chorus         | <audio controls preload="metadata"><source src="/music-generation/ai-chorus.mp3" type="audio/mpeg"></audio>        |
| AI bridge         | <audio controls preload="metadata"><source src="/music-generation/ai-bridge.mp3" type="audio/mpeg"></audio>        |


### Human versus AI - violin solo

I'm also working on a little bluegrass song with a section containing a couple solos; the first half is a guitar solo, and the second half is a violin.
I hired Jory Lane through Musiversal for the violin solo.
For the AI generation, I prompted "_I uploaded the first solo section of a bluegrass song. I want you to create another section in that same style but instead of the guitar soloing, I want a fiddle solo._"

| Actual Guitar and Violon solos                                                                                | AI-generated Violin solo                                                                                  |
|---------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|
| <audio controls preload="metadata"><source src="/music-generation/actual-solo.mp3" type="audio/mpeg"></audio> | <audio controls preload="metadata"><source src="/music-generation/ai-solo.mp3" type="audio/mpeg"></audio> |

## Will AI music make the world a better place?

Fuck no. Best case scenario is that more people will have access to interesting instruments and mashups via prompt. More likely is that the world will be flooded with slop as companies work to eliminate artists and royalties to maximize profit.

## Can you make amazing music today with remote music professionals?

Fuck yeah. It's easier than ever, and it's awesome.

